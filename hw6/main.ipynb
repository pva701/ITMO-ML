{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pnd\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne.updates import adam\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_csv = pnd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.60411121861\n",
      "(89164901, 3)\n"
     ]
    }
   ],
   "source": [
    "table = np.int32(table_csv.as_matrix())\n",
    "\n",
    "table[:, 2] -= 1\n",
    "users_n = len(np.unique(table[:, 0]))\n",
    "films_n = len(np.unique(table[:, 1]))\n",
    "valid_size = int(0.1 * len(table))\n",
    "valid = table[-valid_size:]\n",
    "table = table[:-valid_size]\n",
    "\n",
    "mu = table[:, 2].mean()\n",
    "\n",
    "#mu_u_sm = np.zeros((users_n, 5), dtype=np.float32)\n",
    "#counter = Counter(zip(table[:, 0], table[:, 2]))\n",
    "#for (u,r), c in counter.items():\n",
    "#    mu_u_sm[u][r] += c/(sum(counter[u,i] for i in range(0, 5)))\n",
    "#    \n",
    "#mu_f_sm = np.zeros((films_n, 5), dtype=np.float32)\n",
    "#counter = Counter(zip(table[:, 1], table[:, 2]))\n",
    "#for (f,r), c in counter.items():\n",
    "#    mu_f_sm[f][r] += c/(sum(counter[f,i] for i in range(0, 5)))\n",
    "\n",
    "print(mu)\n",
    "print(table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480189, 17770)\n",
      "(89164901, 3)\n"
     ]
    }
   ],
   "source": [
    "print((users_n, films_n))\n",
    "print(table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = 40\n",
    "U = theano.shared(np.float32(np.random.normal(0, 0.01, (users_n, f))))\n",
    "F = theano.shared(np.float32(np.random.normal(0, 0.01, (films_n, f))))\n",
    "bu = theano.shared(np.float32(np.random.normal(0, 0.01, users_n)))\n",
    "bf = theano.shared(np.float32(np.random.normal(0, 0.01, films_n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f_sm = 40\n",
    "#U_sm = theano.shared(np.float32(np.random.normal(0, 0.01, (users_n, f_sm))))\n",
    "#F_sm = theano.shared(np.float32(np.random.normal(0, 0.01, (films_n, f_sm, 5))))\n",
    "#bu_sm = theano.shared(np.float32(np.random.normal(0, 0.01, users_n)))\n",
    "#bf_sm = theano.shared(np.float32(np.random.normal(0, 0.01, films_n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_batch, film_batch = T.ivector(), T.ivector()\n",
    "lmbd = 0.02\n",
    "ratings = T.ivector()\n",
    "predict = mu + bu[user_batch] + bf[film_batch] + T.batched_dot(U[user_batch], F[film_batch])\n",
    "loss = ((predict-ratings)**2).mean()**0.5 +\\\n",
    "        lmbd*(T.mean(U[user_batch]**2) +\\\n",
    "              T.mean(F[film_batch]**2) +\\\n",
    "              T.mean(bu[user_batch]**2) +\\\n",
    "              T.mean(bf[film_batch]**2))\n",
    "updates = adam(loss, [U, F, bu, bf], learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_batch, film_batch = T.ivector(), T.ivector()\n",
    "#lmbd = 0.05\n",
    "#ratings = T.ivector()\n",
    "#predict = T.nnet.softmax((mu_u_sm[user_batch] + mu_f_sm[film_batch]) / 2 +\\\n",
    "#                         bu_sm[user_batch] + bf_sm[user_batch] +\\\n",
    "#                         T.batched_dot(U_sm[user_batch], F_sm[film_batch]))\n",
    "#\n",
    "#loss = (T.nnet.categorical_crossentropy(predict, ratings).mean() +\\\n",
    "#        lmbd*(T.mean(U_sm**2) + T.mean(F_sm**2) + T.mean(bu_sm**2) + T.mean(bf_sm**2)))\n",
    "#    \n",
    "#updates = adam(loss, [U_sm, F_sm, bu_sm, bf_sm], learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([user_batch, film_batch], predict)\n",
    "train_fn = theano.function([user_batch, film_batch, ratings], [loss, predict], updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.431591033935547\n",
      "2.813370704650879\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "batch_size = 1024*1024\n",
    "idxs = np.arange(0, len(table), dtype=np.int32)\n",
    "np.random.shuffle(idxs)  \n",
    "table = table[idxs]\n",
    "print(time.time() - start)\n",
    "start = time.time()\n",
    "train_fn(table[:batch_size, 0], table[:batch_size, 1], table[:batch_size, 2])\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss  0.736817429351\n",
      "train rmse: 0.729591452343\n",
      "valid rmse: 0.866191486417\n",
      "time: 245.78619408607483\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-1a7c9e1228a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "#best_valid = 100.\n",
    "#best_model = (U.get_value(), F.get_value(), bu.get_value(), bf.get_value())\n",
    "#U.set_value(best_model[0])\n",
    "#F.set_value(best_model[1])\n",
    "#bu.set_value(best_model[2])\n",
    "#bf.set_value(best_model[3])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idxs = np.arange(0, len(table), dtype=np.int32)\n",
    "    np.random.shuffle(idxs)\n",
    "    table = table[idxs]\n",
    "    res = 0\n",
    "    cnt = 0\n",
    "    start = time.time()\n",
    "    train_rmse = 0\n",
    "    for i in range(0, len(table), batch_size):\n",
    "        if i + batch_size > len(table):\n",
    "            break\n",
    "        idx = np.arange(i, i+batch_size)\n",
    "        tmp = train_fn(table[idx, 0], table[idx, 1], table[idx, 2])\n",
    "        res += tmp[0]\n",
    "        train_rmse += ((table[idx, 2] - tmp[1])**2).sum()\n",
    "        cnt += 1\n",
    "    print('epoch', epoch)\n",
    "    print('loss ', res/cnt)\n",
    "    print('train rmse:', (train_rmse/(cnt*batch_size))**0.5)\n",
    "    \n",
    "    valid_pred = predict_fn(valid[:, 0], valid[:, 1])\n",
    "    valid_true = valid[:, 2]\n",
    "    valid_scor = ((valid_pred-valid_true)**2).mean()**0.5\n",
    "    if valid_scor < best_valid:\n",
    "        best_valid = valid_scor\n",
    "        best_model = (U.get_value(), F.get_value(), bu.get_value(), bf.get_value())\n",
    "    print('valid rmse:', valid_scor)\n",
    "    print('time:', time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_table = pnd.read_csv('data/test-ids.csv')\n",
    "test = np.int32(test_table.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85994188285434692"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7445184057029456\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "U.set_value(best_model[0])\n",
    "F.set_value(best_model[1])\n",
    "bu.set_value(best_model[2])\n",
    "bf.set_value(best_model[3])\n",
    "\n",
    "predictions = []\n",
    "for i in range(0, len(test), batch_size):\n",
    "    predictions += list(predict_fn(test[:, 1], test[:, 2]))\n",
    "    print(min((i+batch_size), len(test))/len(test))\n",
    "    \n",
    "#predictions = np.array(predictions)\n",
    "with open('s.txt', 'w+') as out:\n",
    "    out.write('Id,Prediction\\n')\n",
    "    for i, p in zip(list(test[:, 0]), predictions):\n",
    "        out.write(str(i) + ',' + str(p) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
